{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport keras\nfrom keras.preprocessing import image\nfrom keras.engine import Layer\nfrom keras.layers import Conv2D, Conv3D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import TensorBoard\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\nfrom skimage.transform import resize\nfrom skimage.io import imsave\nfrom time import time\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\nfrom PIL import Image, ImageFile\nimport cv2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_gray = np.load('/kaggle/input/image-colorization/l/gray_scale.npy')\nimages_lab = np.load('/kaggle/input/image-colorization/ab/ab/ab1.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gray = images_gray[0]\nimage_lab = images_lab[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Initializing with zeros ( or any random number)\nimg = np.zeros((224, 224, 3))\nimg[:, :, 0] = image_gray\nimg[:, :, 1:] = image_lab\n\n# Changing the data type of the img array to 'uint8'\n# Refer the above markdown for it.\nimg = img.astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_ = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n\n\nprint('Gray scale image')\nplt.imshow(image_gray)\nplt.show()\n\nprint('Recreated image')\nplt.imshow(img_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nY=[]\nfor i in range(0,2000):\n    image_gray = images_gray[i]\n    image_lab = images_lab[i]\n    img = np.zeros((224, 224, 3))\n    img[:, :, 0] = image_gray\n    img[:, :, 1:] = image_lab\n    img = img.astype('uint8')\n    img_ = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    new_array=cv2.resize(img_,(256,256))\n    new_array = new_array.astype('float32')\n    new_array /= 255\n    lab = rgb2lab(new_array)\n    try:\n        lab = rgb2lab(new_array)\n        X.append(lab[:,:,0])\n        Y.append(lab[:,:,1:] / 128)\n    except:\n        print('error')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\nY = np.array(Y)\nX = X.reshape(X.shape+(1,))\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nencoder_input = Input(shape=(256, 256, 1,))\nencoder_output = Conv2D(64, (3,3),strides=(2, 2) ,activation='relu', padding='same')(encoder_input)\nencoder_output = Conv2D(128, (3,3),strides=(1, 1), activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(128, (3,3), strides=(2, 2),activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(256, (3,3),strides=(1, 1), activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(256, (3,3),strides=(2, 2), activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(512, (3,3), strides=(1, 1),activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(512, (3,3), strides=(1, 1),activation='relu', padding='same')(encoder_output)\nencoder_output = Conv2D(256, (3,3),strides=(1, 1) ,activation='relu', padding='same')(encoder_output)\n\n#Decoder\ndecoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\nmodel = Model(inputs=encoder_input, outputs=decoder_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())\nmodel.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\nt=model.fit(X,Y,validation_split=0.2,batch_size=2, epochs=500,verbose=1)\nprint(t.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(t.history['accuracy'])\nplt.plot(t.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(t.history['loss'])\nplt.plot(t.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = '/kaggle/input/building/pexels-photo-1105766.jpeg'\n#test = os.listdir(test_path)\nfor imgName in test:\n    color_me = []\n    img = img_to_array(load_img(test))\n    img = resize(img ,(256,256))\n    color_me.append(img)\ncolor_me = np.array(color_me, dtype=float)\ncolor_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\ncolor_me = color_me.reshape(color_me.shape+(1,))\nprint(color_me.shape)\noutput = model.predict(color_me)\noutput = output * 128\n# Output colorizations\nfor i in range(len(output)):\n    result = np.zeros((256, 256, 3))\n    result[:,:,0] = color_me[i][:,:,0]\n    result[:,:,1:] = output[i]\n    imsave(\"result1.png\", lab2rgb(result))\n    x=lab2rgb(result)\n    plt.imshow(x)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}